{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import os.path as osp\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import RRDBNet_arch as arch\n",
    "from PIL import Image\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feaefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Brown distortion model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The radial distortion coefficients model this type of distortion. The distorted points are denoted as (xdistorted, ydistorted):\n",
    "# xdistorted = x(1 + k1*r2 + k2*r4 + k3*r6)\n",
    "# ydistorted= y(1 + k1*r2 + k2*r4 + k3*r6)\n",
    "# x, y — Undistorted pixel locations. x and y are in normalized image coordinates. Normalized image coordinates are calculated from pixel coordinates by translating to \n",
    "#the optical center and dividing by the focal length in pixels. Thus, x and y are dimensionless.\n",
    "# k1, k2, and k3 — Radial distortion coefficients of the lens.\n",
    "# r2 = x2 + y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## architecture of ECGr GAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f38f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_layer(block, n_layers):\n",
    "    layers = []\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(block())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResidualDenseBlock_5C(nn.Module):\n",
    "    def __init__(self, nf=64, gc=32, bias=True):\n",
    "        super(ResidualDenseBlock_5C, self).__init__()\n",
    "        # gc: growth channel, i.e. intermediate channels\n",
    "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "        # initialization\n",
    "        # mutil.initialize_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    '''Residual in Residual Dense Block'''\n",
    "\n",
    "    def __init__(self, nf, gc=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.RDB1 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB2 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB3 = ResidualDenseBlock_5C(nf, gc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.RDB1(x)\n",
    "        out = self.RDB2(out)\n",
    "        out = self.RDB3(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "\n",
    "class RRDBNet(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
    "        super(RRDBNet, self).__init__()\n",
    "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
    "\n",
    "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
    "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
    "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        #### upsampling\n",
    "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "\n",
    "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da339396",
   "metadata": {},
   "source": [
    "## Executing the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'models/RRDB_ESRGAN_x4.pth' \n",
    "device = torch.device('cpu')  \n",
    "\n",
    "test_img_folder = 'LR/*'\n",
    "\n",
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model path {:s}. \\nTesting...'.format(model_path))\n",
    "\n",
    "idx = 0\n",
    "for path in glob.glob(test_img_folder):\n",
    "    idx += 1\n",
    "    base = osp.splitext(osp.basename(path))[0]\n",
    "    print(idx, base)\n",
    "    # read images\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite('results/{:s}_rlt.png'.format(base), output)\n",
    "print(\"Transformation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_distortion(img,distortion_k):\n",
    "    x_dim = img.shape[0]\n",
    "    y_dim = img.shape[1]\n",
    "    img_distorted = np.zeros(img.shape).astype(np.uint8)\n",
    "    \n",
    "    ## assumed the center to be the optical center, can be changed later\n",
    "    x_optic= x_dim//2\n",
    "    y_optic= y_dim//2\n",
    "    x_focal=x_dim//2\n",
    "    y_focal= y_dim//2\n",
    "    k1,k2,k3= distortion_k\n",
    "    r_max = np.sqrt(2) ## since x_norm <=1 and y_norm <=1\n",
    "    scale = 1+ k1*(r_max**2) + k2*(r_max**4) + k3*(r_max**6)\n",
    "    for x in range (x_dim):\n",
    "        for y in range (y_dim):\n",
    "        #Normalized image coordinates are calculated from pixel coordinates by translating to the optical center and dividing by the focal length in pixels.\n",
    "            x_norm = (x-x_optic)/x_focal\n",
    "            y_norm = (y-y_optic)/y_focal\n",
    "        # r= x**2 + y**2 \n",
    "            r = np.sqrt(x_norm**2 + y_norm**2)\n",
    "            x_dist_norm = x_norm*(1+k1*(r**2) + k2*(r**4) + k3*(r**6))/scale\n",
    "            y_dist_norm = y_norm*(1+k1*(r**2) + k2*(r**4) + k3*(r**6))/scale\n",
    "            x_distorted = int(x_dist_norm*x_optic + x_optic) \n",
    "            y_distorted = int(y_dist_norm*y_optic + y_optic) \n",
    "            try:\n",
    "                img_distorted[x_distorted][y_distorted]=img[x][y]\n",
    "            except:\n",
    "                print(\"dimension unmatched\")\n",
    "    return img_distorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"/Users/felixmeng/Desktop/CME291/computer_vision/Original/original_image2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66675eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_RGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_k=[0.01,0.01,0.02]\n",
    "img_distorted= radial_distortion(img,distortion_k)\n",
    "img_distorted = cv.cvtColor(img_distorted, cv.COLOR_RGB2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(img_distorted)\n",
    "im.save(\"LR/img_distorted.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7443e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_distorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1975b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tangential_distortion(img,distortion_p):\n",
    "    x_dim = img.shape[0]\n",
    "    y_dim = img.shape[1]\n",
    "    img_distorted = np.zeros(img.shape).astype(np.uint8)\n",
    "    print(x_dim,y_dim)\n",
    "\n",
    "    ## assumed the center to be the optical center, can be changed later\n",
    "    x_optic= x_dim//2\n",
    "    y_optic= y_dim//2\n",
    "    x_focal=x_dim//2\n",
    "    y_focal= y_dim//2\n",
    "    p1,p2= distortion_p\n",
    "    r_max = np.sqrt(2) ## since x_norm <=1 and y_norm <=1\n",
    "    x_scale = 1+ (2*p1+p2*(r_max**2+2))\n",
    "    y_scale = 1+ (p1*(r_max**2+2)+2*p2)\n",
    "    for x in range (x_dim):\n",
    "        for y in range (y_dim):\n",
    "        #Normalized image coordinates are calculated from pixel coordinates by translating to the optical center and dividing by the focal length in pixels.\n",
    "            x_norm = (x-x_optic)/x_focal\n",
    "            y_norm = (y-y_optic)/y_focal\n",
    "        # r= x**2 + y**2 \n",
    "            r = np.sqrt(x_norm**2 + y_norm**2)\n",
    "            x_dist_norm = (x_norm+(2*p1*x_norm*y_norm+p2*(r**2+2*x_norm**2)))/x_scale\n",
    "            y_dist_norm = (y_norm+(p1*(r**2+2*y_norm**2)+2*p2*x_norm*y_norm))/y_scale\n",
    "            x_distorted = int(x_dist_norm*x_focal + x_optic) \n",
    "            y_distorted = int(y_dist_norm*y_focal + y_optic) \n",
    "            try:\n",
    "               # print(x_distorted,y_distorted,x,y)\n",
    "                img_distorted[x_distorted][y_distorted]=img[x][y]\n",
    "            except:\n",
    "                print(\"dimension unmatched\",x_distorted,y_distorted)\n",
    "                pass\n",
    "                \n",
    "    return img_distorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_RGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "distortion_p=[0.02,0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tang_distorted= tangential_distortion(img,distortion_p)\n",
    "img_tang_distorted = cv.cvtColor(img_tang_distorted, cv.COLOR_RGB2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b698bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tang_distorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(img_tang_distorted)\n",
    "im.save(\"LR/img_tang_distorted.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04807169",
   "metadata": {},
   "outputs": [],
   "source": [
    "distort_limit=2.5\n",
    "shift_limit=0.9\n",
    "interpolation=1\n",
    "border_mode=4\n",
    "value=None\n",
    "mask_value=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca521f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optic_distort=A.augmentations.geometric.transforms.OpticalDistortion(distort_limit,shift_limit,interpolation=1,border_mode=4,value=None,mask_value=None,always_apply=False,p=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1315c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image = optic_distort(image=img)['image']\n",
    "augmented_image = cv.cvtColor(augmented_image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463886fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class albumentations.augmentations.geometric.transforms.OpticalDistortion (distort_limit=0.05, shift_limit=0.05, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5) [view source on GitHub] ¶\n",
    "# Parameters:\n",
    "\n",
    "# Name\tType\tDescription\n",
    "# distort_limit\tfloat, [float, float]\t\n",
    "# If distort_limit is a single float, the range will be (-distort_limit, distort_limit). Default: (-0.05, 0.05).\n",
    "\n",
    "# shift_limit\tfloat, [float, float]\t\n",
    "# If shift_limit is a single float, the range will be (-shift_limit, shift_limit). Default: (-0.05, 0.05).\n",
    "\n",
    "# interpolation\tOpenCV flag\t\n",
    "# flag that is used to specify the interpolation algorithm. Should be one of: cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4. Default: cv2.INTER_LINEAR.\n",
    "\n",
    "# border_mode\tOpenCV flag\t\n",
    "# flag that is used to specify the pixel extrapolation method. Should be one of: cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101. Default: cv2.BORDER_REFLECT_101\n",
    "\n",
    "# value\tint, float, list of ints, list of float\t\n",
    "# padding value if border_mode is cv2.BORDER_CONSTANT.\n",
    "\n",
    "# mask_value\tint, float, list of ints, list of float\t\n",
    "# padding value if border_mode is cv2.BORDER_CONSTANT applied for masks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b814ed6",
   "metadata": {},
   "source": [
    "# Transfer learning from ESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def make_layer(block, n_layers):\n",
    "    layers = []\n",
    "    for _ in range(n_layers):\n",
    "        layers.append(block())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResidualDenseBlock_5C(nn.Module):\n",
    "    def __init__(self, nf=64, gc=32, bias=True):\n",
    "        super(ResidualDenseBlock_5C, self).__init__()\n",
    "        # gc: growth channel, i.e. intermediate channels\n",
    "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
    "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "        # initialization\n",
    "        # mutil.initialize_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lrelu(self.conv1(x))\n",
    "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
    "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
    "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
    "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
    "        return x5 * 0.2 + x\n",
    "\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    '''Residual in Residual Dense Block'''\n",
    "\n",
    "    def __init__(self, nf, gc=32):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.RDB1 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB2 = ResidualDenseBlock_5C(nf, gc)\n",
    "        self.RDB3 = ResidualDenseBlock_5C(nf, gc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.RDB1(x)\n",
    "        out = self.RDB2(out)\n",
    "        out = self.RDB3(out)\n",
    "        return out * 0.2 + x\n",
    "\n",
    "\n",
    "class RRDBNet(nn.Module):\n",
    "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
    "        super(RRDBNet, self).__init__()\n",
    "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
    "\n",
    "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
    "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
    "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        #### upsampling\n",
    "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
    "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fea = self.conv_first(x)\n",
    "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
    "        fea = fea + trunk\n",
    "\n",
    "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
    "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b194db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/RRDB_ESRGAN_x4.pth' \n",
    "device = torch.device('cpu')  \n",
    "\n",
    "test_img_folder = 'LR/*'\n",
    "\n",
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model path {:s}. \\nTesting...'.format(model_path))\n",
    "\n",
    "idx = 0\n",
    "for path in glob.glob(test_img_folder):\n",
    "    idx += 1\n",
    "    base = osp.splitext(osp.basename(path))[0]\n",
    "    print(idx, base)\n",
    "    # read images\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite('results/{:s}_rlt.png'.format(base), output)\n",
    "print(\"Transformation complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
